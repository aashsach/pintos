			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Aashraya Sachdeva <aashraya.sachdeva@csa.iisc.ernet.in>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

1.	struct timer_wait{
		struct list_elem elem;
		int64_t ticks_left;
		struct thread *t;
	};
timer_wait has been added to store all threads which are 
waiting in timer_sleep. It contains thread along with the time 
duration for which its is supposed to sleep.

2. struct list timer_wait_list
It is used to make a list of timer_wait for holding all th threads 
meant to sleep.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

Every time a thread calles timer_sleep(), following steps take 
place:
1. The the thread along with the sleeping time is stored saved and 
appended in a list.
2. thread is then blocked.
3. timer interrupt decrements value of each thread's sleeping time 
after every tick.
4. Once the sleeping time goes to zero, thread is unblocked.
5. Once thread is unblocked, its corresponding entry from list is 
deleted.
6. The memory taken to save the state of the thread is freed.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

1. Any deletion from the timer_wait_list has been moved to thread's 
own execution. That is thread unblocking after sleeping is 
resposible for deleting its entry from timer_wait_list.
2. Also each thread is resposible for deallocating memory used to save 
its state while it was sleeping.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?
timer_sleep involves storing a threads' state into a list and calling
thread_block(). Thus interrupts are disabled for this process.
Therefore two threads cannot simultaneously execute timer_sleep().

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?
Race conditions occur when the both timer_sleep and timer interrupt 
simultaneously tries to access the list of threads sleeping. They can
be avoided using a global semaphore. The semaphore is decremented while
the timer_sleep is pushing thread onto list. This even if interrupt 
occurs, it would not be able to modify list.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
This design was the easy to implement and took care of all the
functionalities required to be fulfilled. Other design I considered
was to create a flag field in the thread's struct for the marking
how much time thread needs to sleep. However this would have resulted 
in more space even for threads not going to sleep.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread has been added with following new members
	struct thread{
	..
	int absolute_priority;
	struct list lock_list;
	struct lock *waiting_lock;
	..
	};
1. absolute_priority: It holds the actual priority of the thread
independent of the priority donation. It also keeps track of 
thread_set_priority() called by thread itself when it is under
priority donation.

2. lock_list: It is a list of locks currently held by the thread.

3. waiting_lock: pointer to a lock thread is currently waiting for.

struct lock has been added with folloing members
	struct lock{
	..
	struct list_elem elem;
	..
	};
1. elem: It is used so that list of locks could be created.

struct semaphore_elem has been added with following members
	struct semaphore_elem{
	..
	int max_priority;
	..
	};
1. max_priority: holds the maximum priority in the list of
semaphore.waiters for semaphore_elem. It is done to have a quick
sorting for condition structure.	


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

No new data structure have been used to implement priority donation.
However previous data structures were modified. They are
	struct thread{
	..
	int absolute_priority;
	struct list lock_list;
	struct lock *waiting_lock;
	..
	};
1. absolute_priority: It holds the actual priority of the thread
independent of the priority donation. It also keeps track of 
thread_set_priority() called by thread itself when it is under
priority donation.

2. lock_list: It is a list of locks currently held by the thread.
Every time a thread successfully acquires a lock, its entry is made in
this lock.

3. waiting_lock: pointer to a lock thread is currently waiting for.
Every time thread is appended to a lock's waiting list, waiting_lock
is pointed to that lock.



---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

1. Semaphore
Evarytime sema_up() is called, new thread is chosen from its list of
waiters such that thread's priority is maximum in the list.

2. Lock
Evey lock structure has a semaphore structure. Thus lock depends on
the semaphore semantics to implement lock_acquire. Since semaphore
take care of priority, lock is implicitly implied.

3. Condition
Condion structure use list of waiters which in turns contains 
semaphore_elem. Structure semaphore_elem has been added a max_priority
field which tracks the maximum priority in that structure.
Maximum priority thread is chosen by finding maximum on the waiters
list using maximum priority as the key.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

1. lock_try_acquire is called to check whether the lock is available
or not. If available it is immediately given to the thread and lock's
entry is made in thread's lock-list.

2. If lock is not available, thread requesting lock's priority is 
compared with thread holding lock's priority. If former is greater 
than latter, latter's priority is incremented to former's priority. 
And former's waiting_lock is set to this lock.

3. A function donate_priority is used for donation which recursively
checks for thread's waiting lock and increments priority of every
lock's owner in the rcursive calls. Thus handling nested priority.

4. When a thread acquires lock after exiting sema_down, its 
waiting_lock is set to NULL and the lock is appended to its lock_list.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

1. The lock's entry from the current thread's lock_list is deleted.

2. sema_up is called for that lock. This in turn waked up the thread
having maximum priority for the lock in the waiting list.

3. Thread previously holding the lock gives up its priority in one of
fllowing ways:
	3.1. It's priority comes down to maximum of all thread's 
	priority which are part of lock_list's waiters for the current 
	thread (if it is greater than absolute priority).
	3.2 It comes to absolute priority.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?
Thread_set_priority is called by a hread wanting its own priority to 
be changed. There is no as such race in calling of this function,
however a race may occur if priority is to be changed by thread and
in priority donation, a possible race for updating priority may occur.
It is avoided by disabbling interrups when prioriy donation or lock_acquire is being executed.
No, a lock cannot be used.
 

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
This design is pretty straighforward and elegant way of incorporating
all the features required to be implemented into pintos.
The other I considered was to keep the list sorted at all times.
However that would hav increased overhead of finding the right place
in the list at every insertion. In addtion list would have to be
resorted after every updation of priority in advanced scheduler.

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
	struct thread{
	..
	int rec_cpu;
	int nice;
	..
	};
1. rec_cpu: Keeps track of recent CPU time of the thread. Initialized
to 0 for main thread and to parent-thread's rec_cpu otherwise.
2. nice: Stores nice value for each thread. Initialized to 0 for main
thread and to parent-thread's nice value otherwise.

	static int load_avg;
1.load_avg: Keeps track of system's laod average. Initialized to 0.

	#define float_constant 1<<14
1. float_constant: It is extensively used in computing floating point
functions.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0	0   0   0  63  61  59	  A
 4	4   0   0  62  61  59	  A
 8	8   0   0  61  61  59     B
12	8   4   0  61  60  59     A
16	12  4   0  60  60  59	  B
20	12  8   0  60  59  59     A
24	16  8   0  59  59  59     C
28	16  8   4  59  59  58	  B 
32	16  12	4  59  58  58	  A
36	20  12  4  58  58  58	  C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?
The ambiguity was which thread to run if after updating priorities 
two or more threads have same priority. I used the order in which
threads are present in the ready queue to determine the order of
execution.
Yes, this matches behaviour of my scheduler.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?
If the code inside interrupt context is big then more cpu time will 
be spent executing that code. Thus it will affect the recent cpu time
of threads, in turn affecting load average of the system.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?
Advantages
1. Simple and strihtforward implementation.
2. Minimal modification in predefined definitions of data structures.

Disadvantages
1. Setting interrupts off instaed of using locks and semaphores.
2. No indepth analysis of how the load_avg is affected by different
designs considered for implementation.
3. No deadlock detection.
4. Some race conditions are not handled.
5. No floating-point over-flow detection.

If given extra time, I would have tried to eliminate the above listed
disadvantages.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?
I have included a pretty straight forward implementation of floating point math. The operation mentoned in the manual have been implemnted
in simple functions. I have not used ant abstaction layer for the sake
of simplicity and saving time in exection of floating-points. 
However, overflow of floating-points is not checked.


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?=======
